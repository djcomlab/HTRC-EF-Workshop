{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Frequencies and Stopword lists\n",
    "\n",
    "Now we'll look at a look using relative frequencies. Relative frequencies are one way at looking at top words, through their proportional counts. Books have different lengths, so the nominal count of any given word will vary between books, so relative frequencies give us a way to compare two or more books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from htrc_features import FeatureReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load raw lowercased counts for one book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1 = FeatureReader('data/mdp.39015054055697.json.bz2').first()\n",
    "print(\"Loading tokens for\", vol1.title, vol1.enumeration_chronology)\n",
    "tokens = vol1.tokenlist(pages=False, pos=False, case=False)\n",
    "tokens = tokens.loc['body'] # Only focus on section='body'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get relative frequencies, you just need to dived each token count by the total count of words.\n",
    "\n",
    "The total can be retrieved with `tl['count'].sum()`, which takes the `count` column and sums it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing is as easy as taking the count column and diving with `/`. Run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens / tokens['count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, what if we want to save it? It's possible to save to a new column by referring with `tokens['new_column_name'] = ...`. Let's do that, saving our relative frequencies to a `rel_freq` column and sorting by the new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['rel_freq'] = tokens['count'] / tokens['count'].sum()\n",
    "tokens = tokens.sort_values('rel_freq', ascending=False)\n",
    "tokens.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.head(15).plot(y='rel_freq', kind='bar', title='Common token frequencies in ' + vol1.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword lists\n",
    "Not that interesting, right?\n",
    "\n",
    "This is where stopword lists are useful. A stopword list is a pre-built list of words to ignore. We can load one included with the Natural Language Toolkit (nltk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we might remove the words in our stopword list. While we're at it, let's drop words that are not alphabetical words, which will remove tokens like `,` and `1`. For now, you can just copy/paste the below code, but you're always welcome to tinker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1 = tokens[~tokens.index.isin(stopwords.words('english')) & tokens.index.str.isalpha()]\n",
    "subset1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1.head(15).plot(y='rel_freq', kind='bar', title='Common token frequencies in ' + vol1.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together:\n",
    "\n",
    "We've been working really slowly through many of these pieces, but we really didn't craft too much code along the way.  Below we have much of it all working together to answer some really specific questions about our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1 = FeatureReader('data/mdp.39015054055697.json.bz2').first()\n",
    "tokens = vol1.tokenlist(pages=False, pos=False, case=False)\n",
    "tokens = tokens.loc['body'] # Only focus on section='body'\n",
    "subset1 = tokens[~tokens.index.isin(stopwords.words('english')) & tokens.index.str.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focusing only on a Part of Speech\n",
    "\n",
    "Another way to look at notable words is through parts-of-speech. e.g. focusing on `NNP` (proper nouns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = vol1.tokenlist(pages=False, pos=True, case=True).loc['body']\n",
    "proper_nouns_v1 = tokens.loc[(slice(None), ('NNP')),].sort_values('count', ascending=False) # Select NNP and sort\n",
    "proper_nouns_v1['rel_freq'] = proper_nouns_v1['count'] / proper_nouns_v1['count'].sum()     # Calculate Relative frequency\n",
    "proper_nouns_v1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing relative frequencies\n",
    "\n",
    "The value of relative frequencies is that it is easy to compare multiple books. First, let's load volume two of `Lord of the Rings` to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol2 = FeatureReader('data/mdp.39015003763490.json.bz2').first()\n",
    "tokens = vol2.tokenlist(pages=False, pos=True, case=True).loc['body']\n",
    "proper_nouns_v2 = tokens.loc[(slice(None), ('NNP')),].sort_values('count', ascending=False)\n",
    "proper_nouns_v2['rel_freq'] = proper_nouns_v2['count'] / proper_nouns_v2['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_nouns_v1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_nouns_v2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the index of 'token' and 'pos' is the same, you can just subtract one DataFrame from another and the code will know to align the rows (i.e. subtracting the `(Frodo, NNS)` information).\n",
    "\n",
    "Above, we see that Frodo fell from 9% of volume 1 to 6% of volume 2. Which words increased in usage? To find that out, let's subtract the relative frequencies and sort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_books = (proper_nouns_v2 - proper_nouns_v1)\n",
    "compare_books.sort_values('rel_freq', ascending=False).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it!\n",
    "\n",
    "# Exercises\n",
    "\n",
    "Try comparing relative frequencies between two books that you choose, either using parts-of-speech or a stopword list to remove less interesting words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
