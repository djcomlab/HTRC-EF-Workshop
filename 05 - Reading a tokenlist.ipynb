{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a new notebook, we need to import the library and load the volume again. As we go along, run the code cells to see the outputs in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href='http://hdl.handle.net/2027/nyp.33433074811310'>June / by Edith Barnard Delano ; with illustrations.</a></strong> by <em>Delano, Edith Barnard 1874-1946 ,Storer, Florence. ill ,Riverside Press prt ,Houghton Mifflin Company pbl </em> (1916, 274 pages) - <code>nyp.33433074811310</code>"
      ],
      "text/plain": [
       "<htrc_features.feature_reader.Volume at 0x2003a646390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from htrc_features import FeatureReader\n",
    "vol = FeatureReader('data/sample-file1.json.bz2').first()\n",
    "vol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Token List\n",
    "\n",
    "The information contained in `vol.tokens_per_page()` is minimal, a sum of all words in the body of each page. \n",
    "The Extracted Features dataset also provides token counts with much more granularity: for every part of speech (e.g. noun, verb) of every occurring capitalization of every word of every section (i.e. header, footer, body) of every page of the volume. \n",
    "\n",
    "`tokens_per_page()` only kept the \"for every page\" grouping; `vol.tokenlist()` can be called to return section-, part-of-speech-, and word-specific details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tl = vol.tokenlist()\n",
    "# Let's look at some words deeper into the book:\n",
    "# from 1000th to 1100th row, skipping by 15 [1000:1100:15]\n",
    "tl[1000:1100:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the data is returned as a Pandas DataFrame. This time, there is much more information. Consider a single row:\n",
    "\n",
    "<img src=\"images/single-row-tokencount.png\" width=\"300px\" alt=\"Single row of tokenlist.\" />\n",
    "\n",
    "The columns in bold are an index. Unlike the typical one-dimensional index seen before, here there are four dimensions to the index: page, section, token, and pos. This row says that for the 24th page, in the body section (i.e. ignoring any words in the header or footer), the word 'years' occurs 1 time as an plural noun. The part-of-speech tag for a plural noun, `NNS`, follows the [Penn Treebank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) definition.\n",
    "\n",
    "> The \"words\" on the first page seems to be OCR errors for the cover of the book. The HTRC Feature Reader refers to \"pages\" as the $n^{th}$ scanned image of the volume, not the actual number printed on the page. This is why \"page 1\" for this example is the cover.\n",
    "\n",
    "You can sort of see this as nested information, moving beyond how we might normally work with tabular or spreadsheet data.  The blank cells are areas where the data would have normally been duplicated. \n",
    "\n",
    "Tokenlists can be retrieved with arguments (or the stuff that goes inside the `()`) that combine information by certain dimensions, such as `case`, `pos`, or `page`. For example, `case=False` specified that \"Jaguar\" and \"jaguar\" should be counted together. You may also notice that, by default, only 'body' is returned, a default that can be overridden.\n",
    "\n",
    "Look at the following list of commands: can you guess what the output will look like? Try for yourself and observe how the output changes.\n",
    "\n",
    " - `vol.tokenlist(case=False)`\n",
    " - `vol.tokenlist(pos=False)`\n",
    " - `vol.tokenlist(pages=False, case=False, pos=False)`\n",
    " - `vol.tokenlist(section='header')`\n",
    " - `vol.tokenlist(section='group')`\n",
    "\n",
    "Details for these arguments are available in the code [documentation](http://htrc.github.io/htrc-feature-reader/htrc_features/feature_reader.m.html#htrc_features.feature_reader.Volume.tokenlist) for the Feature Reader or by running the `vol.tokenlist?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "1. Load the volume for this copy of [Pride and Prejudice](https://babel.hathitrust.org/cgi/pt?id=hvd.32044089606552). Did it work? How many pages are there in the volume?\n",
    "\n",
    "2. Load a tokenlist of just the words in the header, not preserving case-sensitivity, or page or part of speech information. Set it to `tl` as we did above.\n",
    "\n",
    "    - How many unique words, or tokens, are there in the header? *Tip: scroll to the bottom of the table view*\n",
    "    - How are the rows sorted?\n",
    "    - What are the most common 'real' words among the tokens?\n",
    "\n",
    "3. `tl` has a sorting method, `tl.sort_values()`. Looking up the documentation, see if you can sort on the `count` column. \n",
    "    - Adapt the above code to sort by 'count' in *descending* order.\n",
    "    \n",
    "4. Looking at word counts in page headers is uncommon - usually you want to ignore them and focus just on the body of the page! Retrieve the top words from Pride and Prejudice, again ignoring page, part of speech, and case information. After sorting, determine:\n",
    "    - What types of tokens are most common overall? When are they useful?\n",
    "    - Which occurs more - `he` or `she`?\n",
    "    - Do we see any person names among the top words?\n",
    "    \n",
    "5. When do we want `case` information? When might we not want it?\n",
    "\n",
    "6. What does `page_freq=True` do when given as an argument to `vol.tokenlist()`? You can look at the documentation (`vol.tokenlist?`) or just try to infer from context.\n",
    "\n",
    "_Compare your answers to the workshop participants around you, and help each other out._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
