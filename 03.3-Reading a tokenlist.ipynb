{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href='http://hdl.handle.net/2027/nyp.33433074811310'>June / by Edith Barnard Delano ; with illustrations.</a></strong> by <em>Delano, Edith Barnard 1874-1946 ,Storer, Florence. ill ,Riverside Press prt ,Houghton Mifflin Company pbl </em> (1916, 274 pages) - <code>nyp.33433074811310</code>"
      ],
      "text/plain": [
       "<htrc_features.feature_reader.Volume at 0x19f6c00dc88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since this is a new notebook, we need to import the library and load the volume again\n",
    "from htrc_features import FeatureReader\n",
    "vol = FeatureReader('data/sample-file1.json.bz2').first()\n",
    "vol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Token List\n",
    "\n",
    "The information contained in `vol.tokens_per_page()` is minimal, a sum of all words in the body of each page. \n",
    "The Extracted Features dataset also provides token counts with much more granularity: for every part of speech (e.g. noun, verb) of every occurring capitalization of every word of every section (i.e. header, footer, body) of every page of the volume. \n",
    "\n",
    "`tokens_per_page()` only kept the \"for every page\" grouping; `vol.tokenlist()` can be called to return section-, part-of-speech-, and word-specific details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <th>section</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">27</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">body</th>\n",
       "      <th>those</th>\n",
       "      <th>DT</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>within</th>\n",
       "      <th>IN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">body</th>\n",
       "      <th>a</th>\n",
       "      <th>DT</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <th>VB</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deserted</th>\n",
       "      <th>VBN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faintly</th>\n",
       "      <th>RB</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>important</th>\n",
       "      <th>JJ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count\n",
       "page section token     pos       \n",
       "27   body    those     DT       1\n",
       "             within    IN       1\n",
       "28   body    a         DT       3\n",
       "             be        VB       1\n",
       "             deserted  VBN      1\n",
       "             faintly   RB       1\n",
       "             important JJ       1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl = vol.tokenlist()\n",
    "# Let's look at some words deeper into the book:\n",
    "# from 1000th to 1100th row, skipping by 15 [1000:1100:15]\n",
    "tl[1000:1100:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the data is returned as a Pandas DataFrame. This time, there is much more information. Consider a single row:\n",
    "\n",
    "<img src=\"images/single-row-tokencount.png\" width=\"300px\" alt=\"Single row of tokenlist.\" />\n",
    "\n",
    "The columns in bold are an index. Unlike the typical one-dimensional index seen before, here there are four dimensions to the index: page, section, token, and pos. This row says that for the 24th page, in the body section (i.e. ignoring any words in the header or footer), the word 'years' occurs 1 time as an plural noun. The part-of-speech tag for a plural noun, `NNS`, follows the [Penn Treebank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) definition.\n",
    "\n",
    "> The \"words\" on the first page seems to be OCR errors for the cover of the book. The HTRC Feature Reader refers to \"pages\" as the $n^{th}$ scanned image of the volume, not the actual number printed on the page. This is why \"page 1\" for this example is the cover.\n",
    "\n",
    "You can sort of see this as nested information, moving beyond how we might normally work with tabular or spreadsheet data.  The blank cells are areas where the data would have normally been duplicated. \n",
    "\n",
    "Tokenlists can be retrieved with arguments (or the stuff that goes inside the `()`) that combine information by certain dimensions, such as `case`, `pos`, or `page`. For example, `case=False` specified that \"Jaguar\" and \"jaguar\" should be counted together. You may also notice that, by default, only 'body' is returned, a default that can be overridden.\n",
    "\n",
    "Look at the following list of commands: can you guess what the output will look like? Try for yourself and observe how the output changes.\n",
    "\n",
    " - `vol.tokenlist(case=False)`\n",
    " - `vol.tokenlist(pos=False)`\n",
    " - `vol.tokenlist(pages=False, case=False, pos=False)`\n",
    " - `vol.tokenlist(section='header')`\n",
    " - `vol.tokenlist(section='group')`\n",
    "\n",
    "Details for these arguments are available in the code [documentation](http://htrc.github.io/htrc-feature-reader/htrc_features/feature_reader.m.html#htrc_features.feature_reader.Volume.tokenlist) for the Feature Reader.\n",
    "\n",
    "Jupyter provides another convenience here. Documentation can be accessed within the notebook by adding a '?' to the start of a piece of code. Try it with `?vol.tokenlist`, or with other objects or variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "TODO exercises"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
